\documentclass[a4paper,10pt]{article}

\usepackage[english]{babel}
\usepackage[latin1]{inputenc}
% %\usepackage[dvips]{graphicx}
% \usepackage{graphicx}
% \usepackage{amsmath}
% \usepackage{amssymb}
% \usepackage{amsthm}
% \usepackage{color}
% \usepackage{url}
% \usepackage{hyperref}
\usepackage{francois-preamble}

\newcommand{\numpy}{\texttt{numpy}}

\begin{document}

\title{Assignment 1: Linear Algebra, Differential Calculus\\
Vision and Image Processing}
\author{S{\o}ren Olsen, Fran\c{c}ois Lauze}
\date{\today}
\maketitle


\noindent 
This is the first mandatory assignment on the course Vision and Image
Processing. The goal for you is to get familiar with vector and matrix operations as well as some computations of derivatives and gradients.
\bigskip

{\bf This assignment must be solved individually}.  You have to pass
this and the following mandatory assignments and quizzes in order to
pass this course.  If you do not pass the assignment, but you have
made a SERIOUS attempt, you will get a second chance of submitting a
new solution.  
\bigskip

{\bf The deadline for this assignment is Wednesday 25/11, 2020 at 22:00}. 
You must submit your solution electronically via the Absalon homepage. Go to
the assignments list and choose this assignment and upload your
solution prior to the deadline.  Remember to include your name and KU
user name (login for {KU}net) in the solution. 

\section{Vector Matrix Calculations, pen and paper}
\begin{enumerate}
  \item Let $\bv$ be the vector $[-2,3,4,1,a]^T$. Compute $\bv^T\bv$ and $\bv\bv^T$.
  \item Let $A$ and $B$ the following matrices
  $$
  A = \begin{bmatrix}
    1 & -6 & 1\\
    2 & -4 & 5\\
    8 & 6 & 1
  \end{bmatrix},
  \quad
  B = \begin{bmatrix}
    2 & 3\\ -3 & 7\\ -1 &1
  \end{bmatrix}
  $$
  Compute $\bv = B.[x,y]^T$, $\bw = A.\bv$. Then compute $C = A.B$ and $\bz = C.[x,y]^T$.
  \item Let $A$ be the matrix:
  $$
  A = \begin{bmatrix}
  x-3&  -x+3&  -x+5\\
  x-2&  -x+2&  -x+4&\\
   -1&   1&   -1&
   \end{bmatrix}
  $$
  Compute respectively $A^2 = A.A$ and $A^3 = A.A.A$. Such a matrix $A$ is called \emph{nilpotent}.
  \item Let $A$ be the matrix
  $$
  A = \begin{bmatrix}
    3 & 0 & 4\\
    -2 & 1 & -2\\
    2 & 0 & 3 
  \end{bmatrix}
  $$
  Let $\be_1 = [1,0,0]^T$, $\be_2 = [0,1,0]^T$ and $\be_3=[0,0,1]^T$.
  Compute respectively the solutions $\bff_1$, $\bff_2$ and $\bff_3$ of the linear systems 
  $$
  A.\bff_1 = \be_1,\quad A.\bff_2 = \be_2,\quad A.\bff_3 = \be_3.
  $$
  Let $B$ the matrix which columns are respectively $\bff_1$, $\bff_2$ and $\bff_3$. Then compute $A.B$ and $B.A$. What does it mean?
  \item {\bf[optional]} Let $A$ and $B$ be square matrices of size $(n,n)$. Show that $(A.B)^T = B^T.A^T$.
\end{enumerate}


\section{Vector Matrix Calculations, Python}
In this exercise, you are supposed to use Python and the \texttt{numpy} package. If you know Matlab, you can adapt the calculations to it.

From your preferred Python programming environment, you should start by loading \texttt{numpy} by importing it. It is standard to shorten \texttt{numpy} as \texttt{np}.
See the slides for array declaration.
\begin{verbatim}
  >> import numpy as np
\end{verbatim}
Just to get your hands in the computations! 
\begin{itemize}
  \item An inner and an outer product.  Compute the inner product of
   \begin{center}
     \texttt{a = np.array([1,4,-5,3])} and \texttt{b = np.array([3,-1,0,2])}.
   \end{center}
   Use \texttt{np.dot()} or, preferably, the infix notation \texttt{@}. Computing the outer product requires some extra work. Display the \emph{shape} of \texttt{a}, \texttt{b}.
   and \texttt{b.T} (\texttt{b.shape} and \texttt{b.T.shape}). To force Python-\numpy{} to distinguish between column and line vectors, 1D arrays can be reshaped: Try this piece of code interactively:
   \vspace{-3mm}
   \begin{verbatim}
>> print(a@b)
>> a.shape = (4,1) # a matrix with 1 column (a column vector)
>> b.shape = (4,1) # a matrix with 1 column (a column vector)
>> print(a)
>> print(b)
>> print(b.shape)
>> print(b.T.shape)
>> print(a@b)
>> print(a.T@b)
>> print(float(a.T@b))
>> print(a@b.T)
   \end{verbatim}\vspace{-6mm}
  What do you get?
  \item Let $\bt = [2,0,-1]^T$. Compute the cross-product $\bt\times \bt$ of $\bt$ and itself. (\numpy{} has a cross-product operation, feel free to implement yours).
  Let $\ba = [-2,6,1]^T$. Compute $\bb = \bt\times \ba$ and $\bc = \ba\times \bt$. Then compute the inner products $\bt^T\bb$ and $\ba^T \bb$. 
\end{itemize}  
To a 3D vector $\bt$, one associates the matrix
$$
\hat{\bt} = \begin{bmatrix}
  0 & -t_3 & t_2\\
  t_3& 0 & -t_1\\
  -t_2 & t_1 & 0
\end{bmatrix}
$$
\begin{itemize}
  \item Write a function that takes a 3D vector $\bt$ and associates the corresponding matrix $\hat{\bt}$.
    With $\bt$ and $\ba$ from the previous question, compute $\hat{\bt}\bt$ (matrix vector product) as well as $\hat{\bt}\ba$. What do you get? 
  \item For a 3D vector $\bv$, the operation $\bv\mapsto \bt\times \bv$ is \emph{linear}. So it can be represented by a matrix. Which one? 
  \item Check that $\hat{\bt}^T = -\hat{\bt}$. Compute  $\hat{\bt}^2 = \hat{\bt}.\hat{\bt}$ (matrix-matrix product). What is the transpose of $\hat{\bt}^2$? What about $\hat{\bt}^3 = \hat{\bt}.\hat{\bt}.\hat{\bt}$?
  You may want first to perform numerical computations in Python! 
\end{itemize}

\section{Derivatives}
Functions of one variable.
\begin{itemize}
  \item Compute the derivative $f'(x)$ of $f(x) = e^{-\frac{x^2}{2}}$ (hint: use the chain rule for the exponential, see the tables below.)
  \item Compute its second derivative, $f''(x)$. (hint: reuse the previous rule and Leibniz rule).
  \item Plot on the same graph $f(x)$, $f'(x)$ and $f''(x)$, say for $x\in[-7,7]$ (easy with Python's \texttt{matplotlib}).
  \item Compute the derivative $g'(t)$ of $g(t) = \cos(t)/\sin(t)$.
\end{itemize}
Functions of several variables. This exercise uses many of the derivation rules!
\begin{itemize}
  \item Let $f(x,t)$ be the Gaussian distribution function of variance $t$,
  $$
  f(x,t) = \frac1{\sqrt{2\pi t}}e^{-\frac{x^2}{2t}}.
  $$
  \item Compute $\pder{f}{x}(x,t)$, the first partial derivative of $f(x,t)$ with respect to $x$ (remember that you have to assume that $t$ is fixed and you use the rules of derivation for a function of one variable).
  It is also called the $x$-derivative of $f(x,t)$.
  \item Compute $\pder{f}{t}(x,t)$, the $t$-derivative of $f(x,t)$.
  \item Compute $\pderd{2}{f}{x^2}(x,t)$, the second partial derivative of $f$ with respect to $x$, this is the $x$-derivative of $\pder{f}{x}(x,t)$.
  \item Then show that 
  $$
  \pder{f}{t}(x,t) = \frac12\pderd{2}{f}{x^2}(x,t)
  $$
  This is an extremely important property of this function, especially for many computer vision applications, where $t$ will play the role of a \emph{spatial scale parameter}.
  \item Plot these functions for $t=1,2,4$, with $x\in [-15,15]$.
\end{itemize}

\section{Some derivation rules and classical derivatives}
\renewcommand{\arraystretch}{1.2}
Standard derivation rules: $f(x)$, $g(x)$ are functions of the real variable $x$, $\lambda $ is a real number.
The first derivative is denoted by $f'(x)$, the second by $f''(x)$ (the third is often denoted by by $f'''(x)$ while, in general, for higher order, say $n$, the $n$-th derivative is denoted by $f^{(n)}(x)$).
\renewcommand{\arraystretch}{1.5}
\begin{center}
  \begin{tabular}{|c|c|l|}
  \hline
    function & derivative & rule name\\
    \hline
    $\lambda f(x)$ & $\lambda f'(x)$ & scalar multiplication rule\\
    \hline
    $f(x) + g(x)$ & $f'(x) + g'(x)$ & sum rule\\
    \hline
    $f(x)g(x) $ & $f'(x)g(x) + f(x)g'(x)$ & Leibniz rule\\
    \hline
    $\frac{f(x)}{g(x)}$& $\frac{f'(x)g(x)-f(x)g'(x)}{g(x)^2}$ & quotient rule\\
    \hline
    $f(g(x))$ & $f'(g(x)) g'(x)$ & chain rule\\
    \hline
    $e^{f(x)}$ & $f'(x)e^{f(x)}$ & exponentiation rule (chain rule!)\\
    \hline
    $\ln|f(x)|$ & $\frac{f'(x)}{f(x)}$ & logarithm rule \\
    \hline
    $(f(x) g(x))''$ & $f''(x)g(x) + 2f'(x)g'(x) + g''(x)$ & iterated Leibniz rule\\
    \hline
  \end{tabular}
\end{center}

\begin{center}
Some classical derivatives\\
~\\
  \begin{tabular}{|c|c|l|}
    \hline
    function & derivative & domain/remark \\\hline
    $x^\alpha$ & $\alpha x^{\alpha -1}$ & if $\alpha$ is not an integer, $x$ should be $> 0$\\
    \hline
    $e^x$ & $e^x$& $x\in \RR$\\
    \hline
    $\ln x$ &$\frac1x$ & $x > 0$\\
    \hline
    $\sqrt{x}$ & $\frac1{2\sqrt{x}}$ & special case of first rule with $\alpha = \frac12$, $x>0$\\
    \hline
    $\cos x$ & $-\sin x$ &$x\in \RR$\\
    \hline
    $\sin x$ & $\cos x$ & $x\in \RR$\\
    \hline
    $\tan x$ & $\frac1{\cos^2 x}$ &  $x\not= k\pm\frac\pi2,k\in \ZZ$\\
    \hline
    $\arcsin x$ & $\frac1{\sqrt{1-x^2}}$ & $-1<x<1$\\
    \hline
    $\arccos x$ & $-\frac1{\sqrt{1-x^2}}$ & $-1<x<1$\\
    \hline
    $\arctan x$ & $\frac1{1+x^2}$ &$x\in \RR$\\
    \hline
  \end{tabular}
  \bigskip
\end{center}
  
\section{A few things about Python and Maltab}
In Python with \texttt{numpy},  the \texttt{numpy.dot()} function can be use for inner products, matrix vector products, as well as matrix matrix products. From Python $3.6$ at least and the corresponding \texttt{numpy} package,
one can also use the \emph{infix} notation $@$.  In Python-\texttt{numpy}, the transpose of a array $m$ is $m.T$.
The submodule \texttt{linalg} of \texttt{numpy} contains many standard linear algebra operations.

In Matlab almost all variables are matrices. Column vectors are matrices of size $(n,1)$ while line vectors are matrices of size $(n,1)$. The matrix-matrix multiplication simply uses "$*$". Transposition is denoted with an apostrophe,
the transpose of $m$ is $m'$.





\subsection*{A note on relevant software}
We recommend that you select python 3.6 or higher as your programming
language, preferably from Anaconda, with the \texttt{numpy} and \texttt{scipy} packages.
Matlab, C,  C++ may be other possibilities. Still we recommend that you select the language you are  
most confident in. We however assume that you will use Python and \numpy. If you still wish to use another programming language, you should have some knowledge about linear algebra libraries for this language.
With Matlab, this is straightforward, the name itself stands for "MATrix LABoratory".

The focus should be on learning the methods and not 
learning a new programming language. If you wish to use Matlab, you may download and install this from the
``Softwarebiblioteket'' available at KUnet.


\medskip




\end{document}
